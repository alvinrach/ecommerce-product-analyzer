{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c02e61-8a81-47f2-8686-79e40e55131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scraper import Scraper\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7f9ae-7c42-4371-a1e8-8d01811999c5",
   "metadata": {},
   "source": [
    "# 1 Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39463363-878c-45ed-bc26-69bcae277d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '20_tokopedia_products.csv'\n",
    "\n",
    "if csv_name in os.listdir():\n",
    "    data = pd.read_csv(csv_name)\n",
    "else:\n",
    "    a = Scraper()\n",
    "    data = a.get_data()\n",
    "    a.driver.quit()\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    data.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24ca51b-d093-4f07-905a-facddcd173e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUX SET - Wedding Gift | Birthday Hampers | Kado | Hadiah FLUX SET :\n",
      "- RTR : Classic Mini Air Diffuser / Humidifier 220ml Capacity (Include USB Cable for Air Humidifier & cotton sticks)\n",
      "- RTR Aromatherapy Oil : 2 variants @10ml\n",
      "- RTR : Bear Acrylic Night Lamp\n",
      "- Corrugated white box 22x22cm\n",
      "* FREE GREETING CARD\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "print(data.Product[n], data.Description[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e77e588-6dd9-47a2-a3b6-78258beedac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1c0c10-8975-4394-bec7-20590ccde36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0a0d7-213d-482b-a644-c56cf74f4b42",
   "metadata": {},
   "source": [
    "# 2 Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322eaa47-6af7-4448-a02f-e0c9bc47d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler, StandardScaler, RobustScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5097e48-de04-40f3-872c-8ee9e27cf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "def txtprocess(txt):\n",
    "    # Lower the texts\n",
    "    txt = str(txt).lower()\n",
    "    # Remove contractions\n",
    "    txt = contractions.fix(txt)\n",
    "    \n",
    "    # Just pick the alphabet\n",
    "    txt = re.sub(r'[^a-zA-Z]', ' ', txt)\n",
    "    # Fix unnecessary space\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    \n",
    "    txt = ' '.join(txt.split())\n",
    "    \n",
    "    return txt\n",
    "\n",
    "data.Product = data.Product.map(txtprocess)\n",
    "data.Description = data.Description.map(txtprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc5579a-1084-4061-b9db-9c98d8c59c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning stopwords. Omit the negative maker words (I found this quite effective on this case)\n",
    "stop_words = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "stop_words.add('gift')\n",
    "stop_words.add('hampers')\n",
    "stop_words.add('hadiah')\n",
    "stop_words.add('kado')\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    no_stopword_txt = [w for w in txt.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_txt)\n",
    "\n",
    "data.Product = data.Product.map(remove_stopwords)\n",
    "data.Description = data.Description.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b498532b-bebc-4b57-899c-fa706845bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['char_count'] = data['Description'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82caa07d-f4d2-45db-a523-65292e95b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Price = data.Price.str[2:].str.replace('.', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46a5792c-b0c2-4aa2-b830-83a30550a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Top 3 similar products to 'mug couple wedding':\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "0                souvenir pernikahan wedding\n",
      "19               wedding pernikahan handuk x\n",
      "4                  flux set wedding birthday\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "3\n",
      "Top 3 similar products to 'bayi lahiran bayi newborn baby':\n",
      "8                            newborn set baby bayi bayi\n",
      "15              kelahiran bayi baby newborn set newborn\n",
      "6     bayi baby girl boy lahiran perempuan laki laki...\n",
      "7            baby boy set parcel bayi laki laki premium\n",
      "2          zwitsal baby set box paket perlengkapan bayi\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "4\n",
      "Top 3 similar products to 'flux set wedding birthday':\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "1                         mug couple wedding\n",
      "19               wedding pernikahan handuk x\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "12\n",
      "Top 3 similar products to 'mukena tazbiya special exclusive in':\n",
      "3             bayi lahiran bayi newborn baby\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "17        cewe box ulang anniv sempro wisuda\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "13\n",
      "Top 3 similar products to 'x x premium goodie bag paper bag motif tas':\n",
      "7            baby boy set parcel bayi laki laki premium\n",
      "9     set premium reed diffuser and scented candle l...\n",
      "6     bayi baby girl boy lahiran perempuan laki laki...\n",
      "19                          wedding pernikahan handuk x\n",
      "18                          kotak box souvenir x x tali\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "19\n",
      "Top 3 similar products to 'wedding pernikahan handuk x':\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "1                         mug couple wedding\n",
      "4                  flux set wedding birthday\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For product and description\n",
    "tfidf_product = TfidfVectorizer()\n",
    "product_vectors = tfidf_product.fit_transform(data.Product).toarray()\n",
    "\n",
    "tfidf_description = TfidfVectorizer()\n",
    "description_vectors = tfidf_description.fit_transform(data.Description).toarray()\n",
    "\n",
    "product_similarity_matrix = cosine_similarity(product_vectors)\n",
    "description_similarity_matrix = cosine_similarity(description_vectors)\n",
    "\n",
    "# For prices and c\n",
    "normalized_prices = data.Price.values.reshape(1, -1)\n",
    "normalized_char_count = data.char_count.values.reshape(1, -1)\n",
    "\n",
    "scaler = Normalizer() \n",
    "normalized_prices = scaler.fit_transform(normalized_prices)\n",
    "normalized_char_count = scaler.fit_transform(normalized_char_count)\n",
    "\n",
    "normalized_prices = cosine_similarity(normalized_prices)\n",
    "normalized_char_count = cosine_similarity(normalized_char_count)\n",
    "\n",
    "weight_product = 0.4\n",
    "weight_description = 0.3\n",
    "weight_prices = 0.2\n",
    "weight_char_count = 0.1\n",
    "\n",
    "combined_similarity_matrix = (weight_product * product_similarity_matrix) + (weight_description * description_similarity_matrix) + (weight_prices * normalized_prices) + (weight_char_count * normalized_char_count)\n",
    "\n",
    "j = 0\n",
    "for i in range(len(combined_similarity_matrix)):\n",
    "    top_3_similar_indices = combined_similarity_matrix[i].argsort()[::-1][1:6]  # Exclude the current product\n",
    "    top_3_similar_products = data.iloc[top_3_similar_indices]['Product']\n",
    "    if j!=19 and j!=3 and j!=4 and j!=1 and j!=12 and j!=13:\n",
    "        j+=1\n",
    "        continue\n",
    "    print(j)\n",
    "    j+=1\n",
    "    print(f\"Top 3 similar products to '{data.iloc[i]['Product']}':\")\n",
    "    print(top_3_similar_products)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d354aef5-a2f1-4a3c-b6a9-389c9c6096dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Top 3 similar products to 'mug couple wedding':\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "19               wedding pernikahan handuk x\n",
      "4                  flux set wedding birthday\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "3\n",
      "Top 3 similar products to 'bayi lahiran bayi newborn baby':\n",
      "8                            newborn set baby bayi bayi\n",
      "15              kelahiran bayi baby newborn set newborn\n",
      "6     bayi baby girl boy lahiran perempuan laki laki...\n",
      "2          zwitsal baby set box paket perlengkapan bayi\n",
      "7            baby boy set parcel bayi laki laki premium\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "4\n",
      "Top 3 similar products to 'flux set wedding birthday':\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "19               wedding pernikahan handuk x\n",
      "1                         mug couple wedding\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "19\n",
      "Top 3 similar products to 'wedding pernikahan handuk x':\n",
      "14               souvenir pernikahan wedding\n",
      "0                souvenir pernikahan wedding\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "1                         mug couple wedding\n",
      "4                  flux set wedding birthday\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "product_description_vectors = tfidf_vectorizer.fit_transform(data.Product).toarray()\n",
    "\n",
    "feature_matrix = pd.DataFrame(product_description_vectors)\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "j = 0\n",
    "for i in range(len(similarity_matrix)):\n",
    "    top_3_similar_indices = similarity_matrix[i].argsort()[::-1][1:6]  # Exclude the current product\n",
    "    top_3_similar_products = data.iloc[top_3_similar_indices]['Product']\n",
    "    if j!=19 and j!=3 and j!=4 and j!=1:\n",
    "        j+=1\n",
    "        continue\n",
    "    print(j)\n",
    "    j+=1\n",
    "    print(f\"Top 3 similar products to '{data.iloc[i]['Product']}':\")\n",
    "    print(top_3_similar_products)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "cba1b965-1d42-49ce-8447-b828f2da8978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Top 3 similar products to 'mug couple wedding':\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "0                souvenir pernikahan wedding\n",
      "14               souvenir pernikahan wedding\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "3\n",
      "Top 3 similar products to 'bayi lahiran bayi newborn baby':\n",
      "8                            newborn set baby bayi bayi\n",
      "15              kelahiran bayi baby newborn set newborn\n",
      "6     bayi baby girl boy lahiran perempuan laki laki...\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "4\n",
      "Top 3 similar products to 'flux set wedding birthday':\n",
      "0     souvenir pernikahan wedding\n",
      "14    souvenir pernikahan wedding\n",
      "19    wedding pernikahan handuk x\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n",
      "19\n",
      "Top 3 similar products to 'wedding pernikahan handuk x':\n",
      "14               souvenir pernikahan wedding\n",
      "0                souvenir pernikahan wedding\n",
      "16    souvenir mug couple pernikahan wedding\n",
      "Name: Product, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorize 'Product' and 'Description'\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "product_description_vectors = tfidf_vectorizer.fit_transform(data['Product']).toarray()\n",
    "\n",
    "# Normalize 'Price' and reshape\n",
    "normalized_prices = data['Price'].values.reshape(1, -1)\n",
    "normalized_char_count = data['char_count'].values.reshape(1, -1)\n",
    "scaler = Normalizer() \n",
    "normalized_prices = scaler.fit_transform(normalized_prices)\n",
    "normalized_char_count = scaler.fit_transform(normalized_char_count)\n",
    "# normalized_prices = normalize(normalized_prices)\n",
    "# normalized_char_count = normalize(normalized_char_count)\n",
    "\n",
    "# Combine feature vectors\n",
    "feature_matrix = pd.DataFrame(product_description_vectors)\n",
    "# feature_matrix['Normalized_Price'] = normalized_prices[0]\n",
    "# feature_matrix['Normalized_Char_Count'] = normalized_char_count[0]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "# Find the top 3 most similar products for each product\n",
    "j = 0\n",
    "for i in range(len(similarity_matrix)):\n",
    "    top_3_similar_indices = similarity_matrix[i].argsort()[::-1][1:4]  # Exclude the current product\n",
    "    top_3_similar_products = data.iloc[top_3_similar_indices]['Product']\n",
    "    if j!=19 and j!=3 and j!=4 and j!=1:\n",
    "        j+=1\n",
    "        continue\n",
    "    print(j)\n",
    "    j+=1\n",
    "    print(f\"Top 3 similar products to '{data.iloc[i]['Product']}':\")\n",
    "    print(top_3_similar_products)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356ca77-5b6a-4810-a2af-7d8c591bd9a2",
   "metadata": {},
   "source": [
    "Preprocessing product and description\n",
    "\n",
    "-strip | / -\n",
    "-stop words strip\n",
    "-imbuhan strip\n",
    "-char count (theory of orang yang males bace kasi prod desc pendek)\n",
    "\n",
    "1. Price Binning --> rp10k-20k, rp20k-50k, etc\n",
    "2. Product + Description then cosine similarity\n",
    "3. Gabung semua di satu kolom, atau product_souvenir, product_kado etc\n",
    "\n",
    "Metric will be cosine similarity score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-ecommerce-nlp",
   "language": "python",
   "name": ".env-ecommerce-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
